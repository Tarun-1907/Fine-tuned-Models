{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtyeO_xGNxWi",
        "outputId": "22dd171f-1f26-4d7a-f7d7-8ab2811ba8a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created model adapter with id c41712d5-878b-4846-926c-d44bc380730a_model_adapter\n",
            "Asking: ### Instruction: Who is Tarunjit Saha ? \n",
            " ### Response:\n",
            "Generated:  I apologize, but I am not able to provide information on a specific person named Tarunjit Saha as I'm just an AI language model and do not have access to personal information or databases. Additionally, I cannot verify the accuracy of information found on the internet or other sources. It is important to respect people's privacy and only share information that is publicly available and verifiable. If you are looking for information on a particular Tarunjit Saha,\n",
            "Fine-tuning: 1 epochs are done\n",
            "Fine-tuning: 2 epochs are done\n",
            "Fine-tuning: 3 epochs are done\n",
            "Fine-tuning: 4 epochs are done\n",
            "Fine-tuning: 5 epochs are done\n",
            "Fine-tuning: 6 epochs are done\n",
            "Generated response after fine-tuning:  Tarunjit Saha is a ML Architect, and has good knowledge in NLP and LLM's\n"
          ]
        }
      ],
      "source": [
        "# !pip install gradientai\n",
        "import os\n",
        "\n",
        "# from dotenv import load_dotenv\n",
        "# load_dotenv()\n",
        "\n",
        "os.environ['GRADIENT_WORKSPACE_ID']='5d64c496-fa12-47e5-8249-51958b028c8a_workspace'\n",
        "os.environ['GRADIENT_ACCESS_TOKEN']='..............................'                        # Enter your access token here\n",
        "\n",
        "from gradientai import Gradient\n",
        "\n",
        "def main():\n",
        "    gradient = Gradient()\n",
        "\n",
        "    base_model = gradient.get_base_model(base_model_slug=\"llama2-7b-chat\")\n",
        "\n",
        "    new_model_adapter = base_model.create_model_adapter(\n",
        "        name=\"ftmodel\"\n",
        "    )\n",
        "    print(f\"Created model adapter with id {new_model_adapter.id}\")\n",
        "\n",
        "    sample_query = \"### Instruction: Who is Tarunjit Saha ? \\n ### Response:\"\n",
        "    print(f\"Asking: {sample_query}\")\n",
        "\n",
        "    completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "    print(f\"Generated: {completion}\")\n",
        "\n",
        "    # Creating the custom data to fine-tune the model\n",
        "    custom_data=[\n",
        "        { \"inputs\": \"<s>### Instruction:\\n Who is Tarunjit Saha ? \\n ### Response:\\n Tarunjit Saha is a ML Architect, and has good knowledge in NLP and LLM's.</s>\" }\n",
        "    ]\n",
        "\n",
        "    # Defining the parameters for fine-tuning\n",
        "    num_epochs=6\n",
        "    count=0\n",
        "    while num_epochs>count:\n",
        "        print(f\"Fine-tuning: {count+1}nd epoch is done\")\n",
        "        new_model_adapter.fine_tune(samples=custom_data)\n",
        "        count+=1\n",
        "\n",
        "    completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "    print(f\"Generated response after fine-tuning: {completion}\")\n",
        "\n",
        "    # new_model_adapter.delete()\n",
        "    gradient.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}